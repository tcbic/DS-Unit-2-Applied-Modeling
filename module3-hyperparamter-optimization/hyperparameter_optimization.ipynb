{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O67uhlT4MExK"
   },
   "source": [
    "_Lambda School Data Science â€” Applied Modeling_ \n",
    "\n",
    "This sprint, your project is Caterpillar Tube Pricing: Predict the prices suppliers will quote for industrial tube assemblies.\n",
    "\n",
    "# Hyperparameter Optimization ðŸšœ\n",
    "\n",
    "\n",
    "### Objectives\n",
    "- Do cross-validation with independent test set\n",
    "- Use scikit-learn for hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTI5WqnGv2b2"
   },
   "source": [
    "### Install libraries\n",
    "\n",
    "We will continue to use [category_encoders](https://github.com/scikit-learn-contrib/categorical-encoding) and [xgboost](https://xgboost.readthedocs.io/en/latest/).\n",
    "\n",
    "\n",
    "#### category_encoders\n",
    "- Anaconda: `conda install -c conda-forge category_encoders`\n",
    "- Google Colab: `pip install category_encoders`\n",
    "\n",
    "#### xgboost\n",
    "- Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "- Windows: `conda install -c anaconda py-xgboost`\n",
    "- Google Colab: already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsJ7WePuv2b2"
   },
   "outputs": [],
   "source": [
    "# # Uncomment & run for Google Colab\n",
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nh0yfm-0v2b5"
   },
   "source": [
    "### Get data\n",
    "\n",
    "We will continue to use the Caterpillar dataset.\n",
    "\n",
    "#### Option 1. Kaggle web UI\n",
    " \n",
    "Sign in to Kaggle and go to the [Caterpillar Tube Pricing](https://www.kaggle.com/c/caterpillar-tube-pricing) competition. Go to the Data page. After you have accepted the rules of the competition, use the download buttons to download the data.\n",
    "\n",
    "\n",
    "#### Option 2. Kaggle API\n",
    "\n",
    "Follow these [instructions](https://github.com/Kaggle/kaggle-api).\n",
    "\n",
    "#### Option 3. GitHub Repo â€” LOCAL\n",
    "\n",
    "If you are working locally:\n",
    "\n",
    "1. Clone the [GitHub repo](https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling/tree/master/data/caterpillar) locally. The data is in the repo, so you don't need to download it separately.\n",
    "\n",
    "2. Unzip the file `caterpillar-tube-pricing.zip` which is in the data folder of your local repo.\n",
    "\n",
    "3. Unzip the file `data.zip`. \n",
    "\n",
    "4. Run the cell below to assign a constant named `SOURCE`, a string that points to the location of the data on your local machine. The rest of the code in the notebook will use this constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = '../data/caterpillar/caterpillar-tube-pricing/competition_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 4. GitHub Repo â€” COLAB\n",
    "\n",
    "If you are working on Google Colab, uncomment and run these cells, to download the data, unzip it, and assign a constant that points to the location of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHdra08yv2b6"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/caterpillar/caterpillar-tube-pricing.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COK_XFdqv2b7"
   },
   "outputs": [],
   "source": [
    "# !unzip caterpillar-tube-pricing.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IiVjpMN7v2b9"
   },
   "outputs": [],
   "source": [
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE = 'competition_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example solution for last assignment ðŸšœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We considered some questions about this relational data...***\n",
    "\n",
    "### `bill_of_materials`\n",
    "\n",
    "is formatted like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "materials = pd.read_csv(SOURCE + 'bill_of_materials.csv')\n",
    "materials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Would this be a better representation?\n",
    "\n",
    "Could pandas melt, crosstab, and other functions help reshape the data like this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Crosstab | C-1622 | C-1629 | C-1312 | C-1624 | C-1631 | C-1641 | Distinct | Total |\n",
    "|:--------:|:------:|--------|--------|--------|--------|--------|----------|-------|\n",
    "| TA-00001 | 2      | 2      | 0      | 0      | 0      | 0      | 2        | 4     |\n",
    "| TA-00002 | 0      | 0      | 2      | 0      | 0      | 0      | 1        | 2     |\n",
    "| TA-00003 | 0      | 0      | 2      | 0      | 0      | 0      | 1        | 2     |\n",
    "| TA-00004 | 0      | 0      | 2      | 0      | 0      | 0      | 1        | 2     |\n",
    "| TA-00005 | 0      | 0      | 0      | 1      | 1      | 1      | 3        | 3     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `components`\n",
    "\n",
    "Contains three representations of each component, in order of decreasing cardinality / granularity:\n",
    "\n",
    "- `component_id`\n",
    "- `name`\n",
    "- `component_type_id`\n",
    "\n",
    "What are the pros & cons of these different representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pd.read_csv(SOURCE + 'components.csv')\n",
    "components.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Here's how we could do some of this data wrangling...***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Get a tidy list of the component id's in each tube assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "materials = pd.read_csv(SOURCE + 'bill_of_materials.csv')\n",
    "\n",
    "assembly_components = materials.melt(id_vars='tube_assembly_id', \n",
    "                                     value_vars=[f'component_id_{n}' for n in range(1,9)])\n",
    "\n",
    "assembly_components = (assembly_components\n",
    "                       .sort_values(by='tube_assembly_id')\n",
    "                       .dropna()\n",
    "                       .rename(columns={'value': 'component_id'}))\n",
    "\n",
    "assembly_components.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Merge with component types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pd.read_csv(SOURCE + 'components.csv')\n",
    "assembly_component_types = assembly_components.merge(components, how='left')\n",
    "assembly_component_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Make a crosstab of the component types for each assembly (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(assembly_component_types['tube_assembly_id'], \n",
    "                    assembly_component_types['component_type_id'])\n",
    "\n",
    "table = table.reset_index()\n",
    "table.columns.name = ''\n",
    "print(table.shape)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Most of the component files have a \"weight\" feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def search_column(name):\n",
    "    for path in glob(SOURCE + '*.csv'):\n",
    "        df = pd.read_csv(path)\n",
    "        if name in df.columns:\n",
    "            print(path, df.shape)\n",
    "            print(df.columns.tolist(), '\\n')\n",
    "\n",
    "search_column('weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Most of the component files have \"orientation\" & \"unique_feature\" binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_threaded = pd.read_csv(SOURCE + 'comp_threaded.csv')\n",
    "comp_threaded['orientation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_threaded['unique_feature'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Read all the component files and concatenate them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.concat((pd.read_csv(path) for path in glob(SOURCE + 'comp_*.csv')), sort=False)\n",
    "columns = ['component_id', 'component_type_id', 'orientation', 'unique_feature', 'weight']\n",
    "comp = comp[columns]\n",
    "comp['orientation'] = (comp['orientation']=='Yes').astype(int)\n",
    "comp['unique_feature'] = (comp['unique_feature']=='Yes').astype(int)\n",
    "comp['weight'] = comp['weight'].fillna(comp['weight'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Engineer features, aggregated for all components in a tube assembly\n",
    "- Components total\n",
    "- Components distinct\n",
    "- Orientation \n",
    "- Unique Feature\n",
    "- Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials['components_total'] = sum(materials[f'quantity_{n}'].fillna(0)  for n in range(1,9))\n",
    "materials['components_distinct'] = sum(materials[f'component_id_{n}'].notnull().astype(int) for n in range(1,9))\n",
    "materials['orientation'] = 0\n",
    "materials['unique_feature'] = 0\n",
    "materials['weight'] = 0\n",
    "\n",
    "for n in range(1,9):\n",
    "    materials = materials.merge(comp, left_on=f'component_id_{n}', right_on='component_id', \n",
    "                                how='left', suffixes=('', f'_{n}'))\n",
    "\n",
    "for col in materials:\n",
    "    if 'orientation' in col or 'unique_feature' in col or 'weight' in col:\n",
    "        materials[col] = materials[col].fillna(0)\n",
    "        \n",
    "materials['orientation'] = sum(materials[f'orientation_{n}'] for n in range(1,9))\n",
    "materials['unique_feature'] = sum(materials[f'unique_feature_{n}'] for n in range(1,9))\n",
    "materials['weight'] = sum(materials[f'weight_{n}'] for n in range(1,9))\n",
    "\n",
    "materials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['tube_assembly_id', 'orientation', 'unique_feature', 'weight', \n",
    "            'components_total', 'components_distinct', 'component_id_1']\n",
    "materials = materials[features]\n",
    "print(materials.shape)\n",
    "materials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read tube data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube = pd.read_csv(SOURCE + 'tube.csv')\n",
    "tube.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge all this data with train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data\n",
    "trainval = pd.read_csv(SOURCE + 'train_set.csv')\n",
    "test = pd.read_csv(SOURCE + 'test_set.csv')\n",
    "\n",
    "# Split into train & validation sets\n",
    "# All rows for a given tube_assembly_id should go in either train or validation\n",
    "trainval_tube_assemblies = trainval['tube_assembly_id'].unique()\n",
    "train_tube_assemblies, val_tube_assemblies = train_test_split(\n",
    "    trainval_tube_assemblies, random_state=42)\n",
    "train = trainval[trainval.tube_assembly_id.isin(train_tube_assemblies)]\n",
    "val = trainval[trainval.tube_assembly_id.isin(val_tube_assemblies)]\n",
    "\n",
    "# Wrangle train, validation, and test sets\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Engineer date features\n",
    "    X['quote_date'] = pd.to_datetime(X['quote_date'], infer_datetime_format=True)\n",
    "    X['quote_date_year'] = X['quote_date'].dt.year\n",
    "    X['quote_date_month'] = X['quote_date'].dt.month\n",
    "    X = X.drop(columns='quote_date')\n",
    "    \n",
    "    # Merge data\n",
    "    X = (X.merge(table, how='left')\n",
    "         .merge(materials, how='left')\n",
    "         .merge(tube, how='left')\n",
    "         .fillna(0))\n",
    "    \n",
    "    # Drop tube_assembly_id because our goal is to predict unknown assemblies\n",
    "    X = X.drop(columns='tube_assembly_id')\n",
    "    return X\n",
    "\n",
    "train_wrangled = wrangle(train)\n",
    "val_wrangled = wrangle(val)\n",
    "test_wrangled = wrangle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Arrange X matrix and y vector (log-transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target = 'cost'\n",
    "X_train = train_wrangled.drop(columns=target)\n",
    "X_val = val_wrangled.drop(columns=target)\n",
    "X_test = test_wrangled.drop(columns='id')\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use xgboost to fit and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "eval_set = [(X_train_encoded, y_train_log), \n",
    "            (X_val_encoded, y_val_log)]\n",
    "model = XGBRegressor(n_estimators=2000, n_jobs=-1)\n",
    "model.fit(X_train_encoded, y_train_log, \n",
    "          eval_set=eval_set, eval_metric='rmse', early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = model.evals_result()\n",
    "train_rmse = results['validation_0']['rmse']\n",
    "val_rmse = results['validation_1']['rmse']\n",
    "epoch = range(len(train_rmse))\n",
    "plt.plot(epoch, train_rmse, label='Train')\n",
    "plt.plot(epoch, val_rmse, label='Validation')\n",
    "plt.ylim(0.15,0.35)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate submission for Kaggle\n",
    "\n",
    "Scores for this submission:\n",
    "\n",
    "- Public: 0.26083\n",
    "- Private: 0.28639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(estimator, X_test, filename):\n",
    "    y_pred_log = estimator.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)  # Convert from log-dollars to dollars\n",
    "    submission = pd.read_csv(SOURCE + '../sample_submission.csv')\n",
    "    submission['cost'] = y_pred\n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "generate_submission(model, X_test_encoded, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwrvaIwzv2cA"
   },
   "source": [
    "## Do cross-validation with independent test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hr-Dt67Gv2cB"
   },
   "source": [
    "Let's take another look at [Sebastian Raschka's diagram of model evaluation methods.](https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html) So far we've been using \"**train/validation/test split**\", but we have more options. \n",
    "\n",
    "Today we'll learn about \"k-fold **cross-validation** with independent test set\", for \"model selection (**hyperparameter optimization**) and performance estimation.\"\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg\" width=\"600\">\n",
    "\n",
    "<sup>Source: https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html</sup>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozuzFo_Pv2cB"
   },
   "source": [
    "The Scikit-Learn docs show a diagram of how k-fold cross-validation works, and explain the pros & cons of cross-validation versus train/validate/test split.\n",
    "\n",
    "#### [Scikit-Learn User Guide, 3.1 Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "> When evaluating different settings (â€œhyperparametersâ€) for estimators, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can â€œleakâ€ into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called â€œvalidation setâ€: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "\n",
    "> However, **by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.**\n",
    "\n",
    "> **A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV.** \n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
    "\n",
    "> In the basic approach, called k-fold CV, the training set is split into k smaller sets. The following procedure is followed for each of the k â€œfoldsâ€:\n",
    "\n",
    "> - A model is trained using $k-1$ of the folds as training data;\n",
    "> - the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "> The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. **This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o10EvckQv2cC"
   },
   "source": [
    "### cross_val_score\n",
    "\n",
    "How do we get started? According to the [Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics), \n",
    "\n",
    "> The simplest way to use cross-validation is to call the [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) helper function\n",
    "\n",
    "However, this isn't _so_ simple with the Caterpillar dataset, because:\n",
    "\n",
    "- We want all rows for a given `tube_assembly_id` to go into the same \"fold.\" (Why? [See the discussion here](https://www.fast.ai/2017/11/13/validation-sets/) under _\"New people, new boats\"_ for a reminder.) We can do this with the `cross_val_score` function, using its `groups` parameter.\n",
    "- For scikit-learn's cross-validation [**scoring**](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter), higher is better. But for regression error metrics, lower is better. So scikit-learn multiplies regression error metrics by -1 to make them negative. That's why the value of the `scoring` parameter is `'neg_mean_squared_error'`. \n",
    "- Scikit-learn doesn't implement RMSE, so we take the square root of MSE. First, we must multiply the scores by -1 to make them positive.\n",
    "- RMSE with the log-transformed target is equivalent to RMSLE with the original target.\n",
    "\n",
    "Put it all together, and k-fold cross-validation with the Caterpillar dataset looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "N-TqB5Hsv2cC",
    "outputId": "ee85485b-80a6-4a92-9366-9de29234d432"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    ")\n",
    "\n",
    "k = 3\n",
    "groups = train['tube_assembly_id']\n",
    "scores = cross_val_score(pipeline, X_train, y_train_log, cv=k, \n",
    "                         scoring='neg_mean_squared_error', groups=groups)\n",
    "print(f'RMSLE for {k} folds:', np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dq-PfpGZSHJ"
   },
   "source": [
    "But the Random Forest has many hyperparameters. We mostly used the defaults, and arbitrarily chose `n_estimators`. Is it too high? Too low? Just right? How do we know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "YCubg7EbjZyT",
    "outputId": "73353aad-af43-45fa-820e-b048a268a7ba"
   },
   "outputs": [],
   "source": [
    "print('Model Hyperparameters:')\n",
    "print(pipeline.named_steps['randomforestregressor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk6o8W7Cv2cE"
   },
   "source": [
    "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" â€”[Francois Chollet](https://books.google.com/books?id=dadfDwAAQBAJ&pg=PA114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8uKvR_pv2cG"
   },
   "source": [
    "### Validation Curve\n",
    "\n",
    "Let's try different parameter values, and visualize \"the border between underfitting and overfitting.\" \n",
    "\n",
    "Using scikit-learn, we can make [validation curves](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html), \"to determine training and test scores for varying parameter values. This is similar to grid search with one parameter.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEIxeNXdv2cF"
   },
   "source": [
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
    "\n",
    "<sup>Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3bbgaP2c3Pr"
   },
   "source": [
    "Validation curves are awesome for learning about overfitting and underfitting. (But less useful in real-world projects, because we usually want to vary more than one parameter.)\n",
    "\n",
    "For this example, let's see what happens when we vary the depth of a decision tree. (This will be faster than varying the number of estimators in a random forest.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "znIz2FPQv2cG",
    "outputId": "691e711c-af56-477f-9692-12a9fe405422"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "pipeline = make_pipeline(ce.OrdinalEncoder(), DecisionTreeRegressor())\n",
    "\n",
    "depth = range(1, 15, 2)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    pipeline, X_train, y_train_log,\n",
    "    param_name='decisiontreeregressor__max_depth', \n",
    "    param_range=depth, scoring='neg_mean_squared_error', \n",
    "    cv=2, groups=groups)\n",
    "\n",
    "train_rmsle = np.sqrt(-train_scores)\n",
    "val_rmsle = np.sqrt(-val_scores)\n",
    "plt.plot(depth, np.mean(train_rmsle, axis=1), color='blue', label='training error')\n",
    "plt.plot(depth, np.mean(val_rmsle, axis=1), color='red', label='validation error')\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUaLgk8Pv2cJ"
   },
   "source": [
    "## Use scikit-learn for hyperparameter optimization\n",
    "\n",
    "To vary multiple hyperparameters and find their optimal values, let's try **Randomized Search CV.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AexbC7fjv2cL"
   },
   "source": [
    "#### [Scikit-Learn User Guide, 3.2 Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. \n",
    "\n",
    "> While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values.\n",
    "\n",
    "> Specifying how parameters should be sampled is done using a dictionary. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the `n_iter` parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RZeZd0RsWZL"
   },
   "source": [
    "For the sake of time, let's just do 5 iterations of randomized search, with 2-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "ZtZQbJQ5v2cM",
    "outputId": "60145aba-241e-4ee1-90bc-f861b4137878"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    RandomForestRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'randomforestregressor__n_estimators': randint(50, 500), \n",
    "    'randomforestregressor__max_features': uniform(), \n",
    "    'randomforestregressor__min_samples_leaf':  [1, 10, 100]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=5, \n",
    "    cv=2, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train_log, groups=groups);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P9M-OOJltM_I",
    "outputId": "31b13d77-fdf2-43ab-ff39-a432091729e8"
   },
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation RMSLE', np.sqrt(-search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oo9-Kbx6uWM3"
   },
   "source": [
    "The score may be underwhelming to you, but it's just a demo. Try it after the lesson, with all your features, for more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q79ipvpgqYwF"
   },
   "source": [
    "### \"Fitting X folds for each of Y candidates, totalling Z fits\" ?\n",
    "\n",
    "What did that mean? What do you think?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLjXNObHuTXx"
   },
   "source": [
    "### Do it with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2FabSX50trkd",
    "outputId": "13637c98-09bb-40fb-fb6d-f89f32a9258c"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'xgbregressor__n_estimators': randint(500, 1000), \n",
    "    'xgbregressor__max_depth': randint(3, 7)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=5, \n",
    "    cv=2, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train_log, groups=groups);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F9NJ7deQuxCC",
    "outputId": "96062026-eb4b-4a01-ab49-7aed109a74dd"
   },
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation RMSLE', np.sqrt(-search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tJr3YZ8xLt-"
   },
   "source": [
    "### See detailed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "IGHRUlY3xF1O",
    "outputId": "e8dc2672-2413-4918-bce9-ca1b6acab8bd"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDZyu6FNyY2l"
   },
   "source": [
    "### Make predictions to submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuWqQUk_yIw4"
   },
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_\n",
    "    \n",
    "generate_submission(pipeline, X_test, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sQiv9s2kOjn"
   },
   "source": [
    "## Try adjusting these hyperparameters in your future projects\n",
    "\n",
    "### Tree ensembles\n",
    "\n",
    "#### Random Forest\n",
    "- class_weight (for imbalanced classes)\n",
    "- max_depth (usually high)\n",
    "- max_features (decrease for more variance)\n",
    "- min_samples_leaf (increase if overfitting)\n",
    "- n_estimators (too low underfits, too high wastes time)\n",
    "\n",
    "#### Xgboost\n",
    "- scale_pos_weight (for imbalanced classes)\n",
    "- max_depth (usually low)\n",
    "- n_estimators (too low underfits, too high overfits)\n",
    "\n",
    "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html).\n",
    "\n",
    "### Linear models\n",
    "\n",
    "#### Logistic Regression\n",
    "- C\n",
    "- class_weight (for imbalanced classes)\n",
    "- penalty\n",
    "\n",
    "#### Ridge / Lasso Regression\n",
    "- alpha\n",
    "\n",
    "#### ElasticNet Regression\n",
    "- alpha\n",
    "- l1_ratio\n",
    "\n",
    "For more explanation, see [**Aaron Gallant's 9 minute video on Ridge Regression**](https://www.youtube.com/watch?v=XK5jkedy17w)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLh5dBMa7d2c"
   },
   "source": [
    "# ASSIGNMENT\n",
    "- Use the Caterpillar dataset (or _any_ dataset of your choice). \n",
    "- Use scikit-learn for hyperparameter optimization with RandomizedSearchCV.\n",
    "- Add comments and Markdown to your notebook. Clean up your code.\n",
    "- Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "Do your assignment [\"the hard way.\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit) _\"If you copy-paste, you are cheating yourself out of the effectiveness of the lessons.\"_\n",
    "\n",
    "### Stretch Goals\n",
    "- Make more Kaggle submissions. Improve your scores! Look at [Kaggle Kernels](https://www.kaggle.com/c/caterpillar-tube-pricing/kernels) for ideas. **Share your best features and techniques on Slack.**\n",
    "- Try combining xgboost early stopping, cross-validation, & hyperparameter optimization, [with the scikit-learn API](https://www.kaggle.com/c/liberty-mutual-group-property-inspection-prediction/discussion/15235#180497), or [the \"regular\" xgboost API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.cv).\n",
    "- In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
    "- _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
    "\n",
    "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
    "\n",
    "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?\n",
    "\n",
    "### Post-Reads\n",
    "- Jake VanderPlas, [_Python Data Science Handbook_, Chapter 5.3](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html), Hyperparameters and Model Validation\n",
    "- Jake VanderPlas, [Statistics for Hackers](https://speakerdeck.com/jakevdp/statistics-for-hackers?slide=107)\n",
    "- Ron Zacharski, [_A Programmer's Guide to Data Mining_, Chapter 5](http://guidetodatamining.com/chapter5/), 10-fold cross validation\n",
    "- Sebastian Raschka, [A Basic Pipeline and Grid Search Setup](https://github.com/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparameter_optimization_cross_validation_REFERENCE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
